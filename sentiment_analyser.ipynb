{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SENTIMENT ANALYSER"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing re for removing url and string for textual data","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install nltk\n","execution_count":3,"outputs":[{"output_type":"stream","text":"Collecting nltk\n  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n\u001b[K     |████████████████████████████████| 1.5 MB 4.4 MB/s eta 0:00:01\n\u001b[?25hCollecting regex>=2021.8.3\n  Downloading regex-2021.10.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n\u001b[K     |████████████████████████████████| 749 kB 40.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk) (1.1.0)\nCollecting click\n  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n\u001b[K     |████████████████████████████████| 97 kB 9.5 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: importlib-metadata in /srv/conda/envs/notebook/lib/python3.6/site-packages (from click->nltk) (4.8.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from importlib-metadata->click->nltk) (3.10.0.2)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from importlib-metadata->click->nltk) (3.6.0)\nInstalling collected packages: regex, click, nltk\nSuccessfully installed click-8.0.3 nltk-3.6.5 regex-2021.10.8\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing components of natural language tool kit","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('punkt')","execution_count":7,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n","name":"stderr"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('wordnet')","execution_count":8,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n","name":"stderr"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating stopwords ","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import  stopwords\nnltk.download('stopwords')\nsw=set(stopwords.words('english'))","execution_count":12,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('training.1600000.processed.noemoticon.csv',encoding='latin-1')\ndf.head(3)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"   0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY  mattycus  \\\n0  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY  mattycus   \n1  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   ElleCTF   \n2  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY    Karoli   \n\n                                               Tweet  \n0  @Kenichan I dived many times for the ball. Man...  \n1    my whole body feels itchy and like its on fire   \n2  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1467810917</th>\n      <th>Mon Apr 06 22:19:53 PDT 2009</th>\n      <th>NO_QUERY</th>\n      <th>mattycus</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['NO_QUERY','Mon Apr 06 22:19:53 PDT 2009','1467810917','mattycus'],axis=1)\ndf.head(3)","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"   0                                              Tweet\n0  0  @Kenichan I dived many times for the ball. Man...\n1  0    my whole body feels itchy and like its on fire \n2  0  @nationwideclass no, it's not behaving at all....","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict={'0':'Token'}\ndf.rename(columns=dict,inplace=True)\ndf.head(3)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"   Token                                              Tweet\n0      0  @Kenichan I dived many times for the ball. Man...\n1      0    my whole body feels itchy and like its on fire \n2      0  @nationwideclass no, it's not behaving at all....","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Token</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(data):\n    processedText = []\n    \n    # Defining regex patterns.\n    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n    userPattern       = '@[^\\s]+'\n    alphaPattern      = \"[^a-zA-Z0-9]\"\n    sequencePattern   = r\"(.)\\1\\1+\"\n    seqReplacePattern = r\"\\1\\1\"\n    \n    for tweet in data:\n        tweet = tweet.lower()\n        \n        # Replace all URls with 'URL'\n        tweet = re.sub(urlPattern,' URL',tweet)\n               \n        # Replace @USERNAME to 'USER'.\n        tweet = re.sub(userPattern,' USER', tweet)        \n        # Replace all non alphabets.\n        tweet = re.sub(alphaPattern, \" \", tweet)\n        # Replace 3 or more consecutive letters by 2 letter.\n        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n        \n        tweetwords = ''\n        for word in tweet.split():\n            if len(word)>1:\n                # Lemmatizing the word.\n                word = wordLemm.lemmatize(word)\n                tweetwords += (word+' ')\n            \n        processedText.append(tweetwords)\n        \n    return processedText","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordLemm = WordNetLemmatizer()\nprocessedtext = preprocess(df['Tweet'])","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1,x2,y1,y2 = train_test_split(processedtext , df['Token'] , train_size = 0.8 , test_size = 0.2 , random_state = 0)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Incoder = TfidfVectorizer(ngram_range=(1,2), max_features=1000000)\nIncoder.fit(x2)\n\n\nx1 = Incoder.transform(x1)\nx2  = Incoder.transform(x2)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_Evaluate(model):\n    \n    # Predict values for Test dataset\n    y_pred = model.predict(x2)\n\n    # Print the evaluation metrics for the dataset.\n    print(classification_report(y2, y_pred))","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearSVC()\nreg.fit(x1, y1)\nmodel_Evaluate(reg)","execution_count":32,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.88      0.93      0.91    159849\n           4       0.74      0.61      0.67     49866\n\n    accuracy                           0.86    209715\n   macro avg       0.81      0.77      0.79    209715\nweighted avg       0.85      0.86      0.85    209715\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=preprocess('are you going?')","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=Incoder.transform(t)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.predict(t)","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}